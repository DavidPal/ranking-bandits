\documentclass{article}

\usepackage{fullpage,amssymb,amsthm,amsmath}

\newcommand{\R}{\mathbb{R}}
\DeclareMathOperator*{\argmin}{argmin}

\begin{document}

\title{Ranking Bandits}
\author{R\'obert Busa-Fekete \and D\'avid P\'al}
\maketitle

\section{Introduction}

Learning a ranking function is one the of the basic problems in information
retrieval systems. Given a user's query, an information retrieval system
retrieves a set of \emph{candidate documents}; this is usually done by a keyword
match. For each of the candidate documents, the system computes a feature vector
(consisting of e.g. PageRank, frequencies of query words in the document and the
corpus, etc.). Based on these feature vectors, a \emph{ranking function}
computes an ordering (\emph{ranking}) of the candidate documents that is meant
to capture the relative relevance of the candidate documents. The user will see
the candidate documents presented in an order from top to bottom according to
this ranking, so that the most relevant documents are at the top and the least
relevant documents are at the bottom. Finally, the user clicks on one of the
documents, which the information retrieval system can observe and
can use it to improve its ranking.

We consider the problem of learning the ranking function from the clicks in
an online fashion. We consider ranking functions which, for every candidate
document, compute a score, that is a linear combination of the features, orders
the documents according to the score in decreasing order. We call such ranking
functions \emph{linear ranking functions}.

We propose a very simple model of user's click behavior. \emph{We assume that the
user, in his mind, together with the query chooses implicitly a set of documents
that are relevant and he clicks on the topmost relevant document.}

We formalize problem as an online learning problem with partial feedback. It can
be viewed as a repeated game between the nature and the learner. Each round $t$
corresponds to a user's query. We denote by $C_t$ the set of candidate documents
in round $t$. For simplicity, we assume that the size of $|C_t| = N$ is the same
in each round. (The problem formulation can be extended to a setting where size
of $C_t$ changes from round to round.) In each round, based on the query, the
set of candidate documents $C_t$, user's features, and any other side
information, the nature produces $N$ feature vectors $x_1^{(t)}, x_2^{(t)},
\dots, x_N^{(t)} \in \R^d$. We can assume without loss of generality $C_t =
\{1,2,\dots,N\}$. Hence, $x_i^{(t)}$ is the feature vector of the document $i$.

We assume that the user chooses a non-empty subset $U_t
\subset C_t = \{1,2,\dots,N\}$ of \emph{relevant documents}. The learning
algorithm chooses an permutation $\pi_t$ of $C_t = \{1,2,\dots,N\}$ and the
documents in $C_t$ are presented to the user in the order induced by $\pi_t$.
That is, document $i \in C_t = \{1,2,\dots,N\}$ is presented at position
$\pi_t(i)$ from the top. We assume that the user clicks on a relevant document
closest to the top. That is, user clicks on the document $i \in U_t$ for which
$\pi_t(i)$ is the smallest.

The protocol of the game can be summarized as follows:

\begin{itemize}
\item Nature produces feature vectors
$x^{(t)}_1, x^{(t)}_2, \dots, x^{(t)}_N \in \R^d$
and non-empty $U_t \subseteq \{1,2,\dots,N\}$.
\item Learner chooses a permutation $\pi_t$ of $\{1,2,\dots,N\}$
\item Learner observes user's click on the document $i_t = \argmin_{i \in U_t} \pi_t$
\end{itemize}

We assume that $Z_t = (U_t, x_1^{(t)}, x_2^{(t)}, \dots x_N^{(t)})$ is generated from
an arbitrary fixed distribution $D$ that is unknown to the learner.
In other words, $\{(U_t, x_1^{(t)}, x_2^{(t)}, \dots
x_N^{(t)})\}_{t=1}^\infty$ is an i.i.d. sequence.

In order to define quality of a ranking, we need to define a suitable loss
function that assigns loss to any pair $(\pi_t, U_t)$. Note that since the loss
depends on $U_t$, it is hidden to the learner.

Ranking loss
\[
\ell_w ( \pi , U ) = \sum_{i=1}^{| U |} w(i) c(i, \pi, U)
\]
where $c_{\pi}(i)$ is the size of the cover of first $i$ items with respect to $\pi$ defined as
\[
c(i, \pi, U ) = \min \left\{ k\in [N] : i = \#\left\{ j \in U : \pi(j) \le k\right\} \right\} \enspace .
\]
Particularly, by using
\[
w_1 ( i )  = 
\begin{cases}
1 & \mbox{ if } i = 1 \\
0 & \mbox{otherwise}
\end{cases}
\]
the ranking loss $\ell ( \pi , U )$ is equal to the minimal ranks of the items from $U$ with respect to $\pi$. The Min sum set cover ({\bf mssc}) problem formalizes the optimization problem of this ranking loss. More detail, for a given set of $U_1, \dots, U_n$, the gaol in {\bf mssc} is to find the permutation that minimizes
$\tfrac{1}{n}\sum_{i=1}^{n} \ell_{w_1} ( \pi, U_n )$.

The online version

\section{Related work}

\begin{itemize}
	\item \cite{Ail14} $| U| =1 $
	\item \cite{RaKlJo08}
	\item \cite{AzarGY09}
	\item Online learning to rank based on Random projection \cite{SchuthOWR16}
\end{itemize}

\bibliography{ltr}{}
\bibliographystyle{plain}

\end{document}
